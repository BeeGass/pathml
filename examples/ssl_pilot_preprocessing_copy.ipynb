{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Workflow (Working Example)\n",
    "\n",
    "This workflow is being used for preprocessing of data for self-supervised learning pilot.\n",
    "\n",
    "### Dataset consists of 400 slides (700Gb)\n",
    "\n",
    "For each slide:\n",
    "\n",
    "1. Detect regions of tissue, using low-resolution image of whole slide\n",
    "2. load full-resolution slide in chunks\n",
    "3. divide each chunk into 224px tiles\n",
    "\n",
    "The ability to define our own custom TileExtractor class allows us to create this pipeline.\n",
    "\n",
    "1. SlideLoader loads low-resolution image into SlideData.image\n",
    "2. SlidePreprocessor performs tissue detection on the low-res image, and puts the mask into SlideData.mask\n",
    "3. TileExtractor:\n",
    "    - dimensions of full-resolution image are divided into 5000px chunks\n",
    "    - for each chunk:\n",
    "        - use SlideData.wsi.read_region() to read full-resolution image for chunk\n",
    "        - get corresponding mask region from tissue detection\n",
    "        - upsample the mask (https://stackoverflow.com/a/32848377)\n",
    "        - divide into tiles\n",
    "        - write each tile to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathml.tiling import extract_tiles_with_mask\n",
    "from pathml.image_utils import pil_to_rgb, upsample_array, plot_mask\n",
    "from pathml.pipeline import Pipeline\n",
    "from pathml.base_preprocessor import (BaseSlideLoader,\n",
    "                                      BaseSlidePreprocessor,\n",
    "                                      BaseTileExtractor,\n",
    "                                      BaseTilePreprocessor)\n",
    "from pathml.transforms_HandE import TissueDetectionHE\n",
    "from pathml.wsi import HESlide\n",
    "from pathml.transforms import ForegroundDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "class MySlideLoader(BaseSlideLoader):\n",
    "    def __init__(self, level):\n",
    "        self.level = level\n",
    "    \n",
    "    def apply(self, path):\n",
    "        data = HESlide(path).load_data(level=self.level)\n",
    "        # add the level as an attribute to the SlideData object so we can access it later\n",
    "        data.level = self.level\n",
    "        return data\n",
    "\n",
    "# step 2\n",
    "class MySlidePreprocessor(BaseSlidePreprocessor):\n",
    "    \"\"\"slide-level preprocessor which detects regions of tissue\"\"\"\n",
    "    def apply(self, data):\n",
    "        # using downsampled image, so need to lower min_region_size for tissue detection\n",
    "        tissue_detector = TissueDetectionHE(\n",
    "            foreground_detection = ForegroundDetection(min_region_size=1000, max_hole_size=1000)\n",
    "        )\n",
    "        tissue_mask = tissue_detector.apply(data.image)\n",
    "        data.mask = tissue_mask\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to the trickier part, which is tile extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTileExtractor(BaseTileExtractor):\n",
    "    \n",
    "    def __init__(self, tile_size=224):\n",
    "        self.tile_size = 224\n",
    "    \n",
    "    def apply(self, data, debug=False):\n",
    "        \"\"\"\n",
    "        Use the downsampled data.mask to get full-resolution tiles. \n",
    "        Process full-resolution image in chunks.\n",
    "        No tile-level preprocessing being performed.\n",
    "        This will also write the tiles\n",
    "        \"\"\"\n",
    "        # get scale for upscaling mask to full-res\n",
    "        scale = data.wsi.slide.level_downsamples[data.level]\n",
    "        scale = int(scale)\n",
    "        # size of each chunk, at low-resolution\n",
    "        chunk_size_low_res = 1000\n",
    "        # size of each chunk, at full-resolution\n",
    "        chunk_size = chunk_size_low_res * scale\n",
    "        # how many chunks in each full_res dim\n",
    "        # note that openslide uses (width, height) format\n",
    "        full_res_j, full_res_i = data.wsi.slide.level_dimensions[0]\n",
    "        \n",
    "        #filepath for saving tiles\n",
    "        if \"testing\" in data.wsi.path:\n",
    "            out_dir = \"/mnt/disks/pilot-data/preprocessed/testing\"\n",
    "        elif \"training\" in data.wsi.path:\n",
    "            if \"tumor\" in data.wsi.path:\n",
    "                out_dir = \"/mnt/disks/pilot-data/preprocessed/training/tumor\"\n",
    "            elif \"normal\" in data.wsi.path:\n",
    "                out_dir = \"/mnt/disks/pilot-data/preprocessed/training/normal\"\n",
    "        if not os.path.exists(out_dir):\n",
    "            os.makedirs(out_dir)\n",
    "        wsi_base_name = os.path.splitext(os.path.basename(data.wsi.path))[0]\n",
    "        \n",
    "        # loop thru chunks\n",
    "        n_chunk_i = full_res_i // chunk_size\n",
    "        n_chunk_j = full_res_j // chunk_size\n",
    "        \n",
    "        for ix_i in range(n_chunk_i):\n",
    "            for ix_j in range(n_chunk_j):\n",
    "                # get mask\n",
    "                mask = data.mask[ix_i*chunk_size_low_res:(ix_i + 1)*chunk_size_low_res, \n",
    "                                 ix_j*chunk_size_low_res:(ix_j + 1)*chunk_size_low_res]\n",
    "                \n",
    "                if mask.mean() == 0.0:\n",
    "                    # empty chunk, no need to continue processing\n",
    "                    continue\n",
    "                \n",
    "                mask_upsampled = upsample_array(mask, scale)\n",
    "                # get full-res image\n",
    "                region = data.wsi.slide.read_region(\n",
    "                    location = (ix_j*chunk_size, ix_i*chunk_size),\n",
    "                    level = 0, size = (chunk_size, chunk_size)\n",
    "                )\n",
    "                region_rgb = pil_to_rgb(region)\n",
    "                \n",
    "                # divide into tiles\n",
    "                good_tiles = extract_tiles_with_mask(\n",
    "                    im = region_rgb, \n",
    "                    tile_size = self.tile_size,\n",
    "                    mask = mask_upsampled\n",
    "                )\n",
    "                \n",
    "                for tile in good_tiles:\n",
    "                    # adjust i and j coords for each tile to account for the chunk offset\n",
    "                    tile.i += ix_i*chunk_size\n",
    "                    tile.j += ix_j*chunk_size\n",
    "                    tile.save(out_dir = out_dir, filename = f\"{wsi_base_name}_{tile.i}_{tile.j}.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose into pipeline\n",
    "class PipelineSSL(Pipeline):\n",
    "    \"\"\"\n",
    "    Preprocessing pipeline for self-supervised learning project.\n",
    "    CAMELYON16 data, with slide-level labels\n",
    "    \"\"\"\n",
    "    def __init__(self, slide_loader, slide_preprocessor, tile_extractor):\n",
    "        self.slide_loader = slide_loader\n",
    "        self.slide_preprocessor = slide_preprocessor\n",
    "        self.tile_extractor = tile_extractor\n",
    "    \n",
    "    def run(self, path, debug=False):\n",
    "        \"\"\"\n",
    "        Run full pipeline\n",
    "        \"\"\"\n",
    "        # load slide\n",
    "        data = self.slide_loader.apply(path)\n",
    "        \n",
    "        # slide-level preprocessing: tissue detection\n",
    "        data = self.slide_preprocessor.apply(data)\n",
    "            \n",
    "        # extract tiles\n",
    "        self.tile_extractor.apply(data, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose into pipeline\n",
    "pipeline_ssl = PipelineSSL(\n",
    "    slide_loader = MySlideLoader(level = 3),\n",
    "    slide_preprocessor = MySlidePreprocessor(),\n",
    "    tile_extractor = MyTileExtractor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all images to run on\n",
    "impaths = glob.glob(\n",
    "    \"/mnt/disks/pilot-data/parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100439/CAMELYON16/**/*.tif\",\n",
    "    recursive = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in tqdm(impaths):\n",
    "    pipeline_ssl.run(im)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "pathML",
   "language": "python",
   "name": "pathml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
